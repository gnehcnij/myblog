# Introduction

**Apache Kafka是一个分布式流式平台。**

**流式平台具有三个关键功能：**

- 发布和订阅记录流，类似于消息队列或企业消息传递系统。
- 以容错的持久方式存储记录流。
- 处理记录流。

**Kafka通常用于两大类应用程序：**

1. 建立实时流数据管道，以可靠地在系统或应用程序之间获取数据。
2. 构建实时流应用程序，以转换或响应数据流。

**首先几个概念：**

- Kafka在一个或多个可以跨越多个数据中心的服务器上作为集群运行。
- Kafka集群将记录流存储在称为*topics*（主题）的类别中。
- 每个记录由一个键，一个值和一个时间戳组成。

**Kafka具有四个核心API：**

-  [Producer API](https://kafka.apache.org/documentation.html#producerapi) 允许应用程序将记录流发布到一个或多个Kafka主题。

- [Consumer API](https://kafka.apache.org/documentation.html#consumerapi) 允许应用程序订阅一个或多个主题并处理为其生成的记录流。

-  [Streams API](https://kafka.apache.org/documentation/streams) 允许应用程序充当流处理器，使用一个或多个主题的输入流，并生成一个或多个输出主题的输出流，从而有效地将输入流转换为输出流。

-  [Connector API](https://kafka.apache.org/documentation.html#connect) 允许构建和运行将Kafka主题连接到现有应用程序或数据系统的可重用生产者或使用者。例如，关系数据库的连接器可能会捕获对表的所有更改。

![kafka-apis.png](../../pic/kafka-apis.png)

在Kafka中，客户端和服务器之间的通信是通过简单，高性能，与语言无关的 [TCP protocol](https://kafka.apache.org/protocol.html) 完成的。该协议已版本化，并与旧版本保持向后兼容性。我们为Kafka提供了Java客户端，但是客户端支持多种 [语言](https://cwiki.apache.org/confluence/display/KAFKA/Clients)。

#### [1. Topics and Logs（主题与日志）](https://kafka.apache.org/intro#intro_topics)

首先，让我们深入探讨Kafka提供的记录记录流的核心抽象-topic（主题）。

topic 是将记录发布到的类别或订阅源名称。Kafka中的 topic 始终是多用户的；也就是说，一个 topic 可以有零个，一个或多个消费者来订阅写入该 topic 的数据。

对于每个topic ，Kafka 集群都会维护一个分区日志（ partitioned log ），如下所示：

![log_anatomy](../../pic/log_anatomy.png)

每个分区都是有序的，不变的记录序列，这些记录连续地附加到结构化的提交日志中。分别为分区中的记录分配了一个顺序ID号，称为偏移号 *offset* ，该ID号唯一标识分区中的每个记录。

Kafka集群使用可配置的保留期限持久保留所有已发布的记录（无论是否已使用它们）。例如，如果将保留策略设置为两天，则在发布记录后的两天内，该记录可供使用，之后将被丢弃以释放空间。Kafka的性能相对于数据大小实际上是恒定的，因此长时间存储数据不是问题。

![log_consumer](../../pic/log_consumer.png)

实际上，基于每个消费者保留的唯一元数据是该消费者在日志中的偏移量或位置。此偏移量由使用者控制：通常，使用者在读取记录时会线性地推进其偏移量，但是实际上，由于位置是由使用者控制的，因此它可以按喜欢的任何顺序使用记录。例如，使用者可以重置到较旧的偏移量以重新处理过去的数据，或者跳到最近的记录并从“现在”开始使用。

这些功能的组合意味着 Kafka 的消费者非常便宜-他们来来去去对集群或其他消费者没有太大影响。例如，您可以使用我们的命令行工具来“tail”任何主题的内容，而无需更改任何现有使用者所消耗的内容。

日志中的分区有多种用途。首先，它们允许日志扩展到超出单个服务器所能容纳的大小。每个单独的分区都必须适合承载它的服务器，但是一个主题可能有很多分区，因此它可以处理任意数量的数据。其次，它们充当并行性的单元-稍有更多。

#### [Distribution（分布式）](https://kafka.apache.org/intro#intro_distribution)

日志的分区分布在Kafka群集中的服务器上，每台服务器处理数据并要求共享分区。每个分区都跨可配置数量的服务器复制，以实现容错功能。

每个分区都有一个充当 “leader” 的服务器和零个或多个充当 “followers” 的服务器。leader 处理对分区的所有读写请求，而 followers 则被动地复制 leader。如果 leader 失败，则跟随者之一将自动成为新 leader。每个服务器充当其某些分区的 leader，而充当其他分区的 followers，因此群集中的负载得到了很好的平衡。

#### [Geo-Replication](https://kafka.apache.org/intro#intro_geo-replication)

Kafka MirrorMaker为您的集群提供地理复制支持。使用MirrorMaker，可以在多个数据中心或云区域中复制消息。您可以在主动/被动方案中使用它进行备份和恢复。或在主动/主动方案中将数据放置在离您的用户更近的位置，或支持数据位置要求。

#### [Producers（生产者）](https://kafka.apache.org/intro#intro_producers)

生产者将数据发布到他们选择的主题。生产者负责选择将哪个记录分配给主题中的哪个分区。可以以轮询方式完成此操作，仅是为了平衡负载，也可以根据某些语义分区功能（例如基于记录中的某些键）进行此操作。一秒钟就可以了解更多有关分区的信息！

#### [Consumers（消费者）](https://kafka.apache.org/intro#intro_consumers)

消费者使用消费者组名称标记自己，并且发布到主题的每条记录都会传递到每个订阅消费者组中的一个消费者实例。消费者实例可以在单独的进程中或在单独的机器上。

如果所有消费者实例都具有相同的消费者组，那么将在这些消费者实例上有效地均衡记录。

如果所有消费者实例具有不同的消费者组，则每个记录将广播到所有消费者进程。

![consumer-groups](../../pic/consumer-groups.png)

由两台服务器组成的 Kafka 群集，其中包含四个带有两个使用者组的分区（P0-P3）。消费者组A有两个消费者实例，组B有四个。

但是，更常见的是，我们发现主题具有少量的消费者组，每个“逻辑订阅者”一个。每个组均由许多消费者实例组成，以实现可伸缩性和容错能力。这无非就是发布-订阅模式，其中订阅者是消费者的集群而不是单个进程。

在 Kafka 中 实现使用的方式是通过在消费者方实例上划分日志中的分区，以便每个实例在任何时间点都是分区“公平份额”的排他使用方。Kafka协议动态处理了维护组成员身份的过程。如果新实例加入该组，它们将接管该组其他成员的某些分区；如果实例死亡，则其分区将分配给其余实例。

Kafka 仅提供分区中记录的总顺序，而不提供主题中不同分区之间的记录顺序。对于大多数应用程序，按分区排序以及按键对数据进行分区的能力就足够了。但是，如果您需要记录的总订单量，则可以使用只有一个分区的主题来实现，尽管这将意味着每个消费者组只有一个消费者流程。

#### [Multi-tenancy （多租户）](https://kafka.apache.org/intro#intro_multi-tenancy)

您可以将 Kafka 部署为多租户解决方案。通过配置哪些主题可以产生或使用数据来启用多租户。配额也有运营支持。管理员可以在请求上定义和实施配额，以控制客户端使用的代理资源。

#### [Guarantees](https://kafka.apache.org/intro#intro_guarantees)

在较高级别上，Kafka 提供以下保证：

- 生产者发送到特定主题分区的消息将按其发送顺序附加。也就是说，如果记录M1是由与记录M2相同的生产者发送的，并且首先发送M1，则M1的偏移量将小于M2，并在日志中更早出现。
- 消费者实例按记录在日志中的存储顺序查看记录。
- 对于具有复制因子N的主题，我们最多可以容忍N-1个服务器故障，而不会丢失任何提交给日志的记录。

#### [Kafka as a Messaging System（Kafka作为消息系统）](https://kafka.apache.org/intro#kafka_mq)

Kafka 的流概念与传统的企业消息传递系统相比如何？

传统上，消息传递有两种模型：队列和发布-订阅。在队列中，一组消费者可以从服务器中读取内容，并且每条记录都将转到其中一个。在发布-订阅记录中广播给所有消费者。这两个模型中的每一个都有优点和缺点。队列的优势在于，它允许您将数据处理划分到多个使用者实例上，从而扩展处理量。不幸的是，队列不是多用户的—一次进程读取了丢失的数据。发布-订阅允许您将数据广播到多个进程，但是由于每条消息都传递给每个订阅者，因此无法扩展处理。

Kafka 的消费者群体概念概括了这两个概念。与队列一样，消费者组允许您将处理划分为一组进程（消费者组的成员）。与发布订阅一样，Kafka 允许您将消息广播到多个消费者组。

Kafka 模型的优点在于，每个主题都具有这些属性-可以扩展处理范围，并且是多订阅者-无需选择其中一个。

与传统的消息传递系统相比，Kafka 还具有更强的顺序保证。

传统队列将记录按顺序保留在服务器上，如果多个使用者从队列中消费，则服务器将按记录的存储顺序分发记录。但是，尽管服务器按顺序分发记录，但是这些记录是异步传递给使用者的，因此它们可能在不同的消费者上乱序到达。这实际上意味着在并行使用的情况下会丢失记录的顺序。消息传递系统通常通过“排他消费者”的概念来解决此问题，该概念仅允许一个进程从队列中使用，但是，这当然意味着在处理中没有并行性。

Kafka 做得更好。通过在主题内具有并行性（即分区）的概念，Kafka 能够在用户进程池中提供排序保证和负载均衡。这是通过将主题中的分区分配给消费者组中的消费者来实现的，以便每个分区都由组中的一个消费者完全消费。通过这样做，我们确保消费者是该分区的唯一读取器，并按顺序使用数据。由于存在许多分区，因此仍然可以平衡许多消费者实例上的负载。但是请注意，消费者组中的消费者实例不能超过分区。

#### Kafka as a Storage System （Kafka 作为存储系统）

任何允许发布与使用无关的消息发布的消息队列都有效地充当了运行中消息的存储系统。Kafka 的不同之处在于它是一个非常好的存储系统。

写入 Kafka 的数据将写入磁盘并进行复制以实现容错功能。Kafka 允许生产者等待确认，以便直到完全复制并确保即使写入服务器失败的情况下写入也不会完成。

Kafka 的磁盘结构可以很好地扩展使用-无论服务器上有50 KB还是50 TB的持久数据，Kafka 都将执行相同的操作。

由于认真对待存储并允许客户端控制其读取位置，因此您可以将 Kafka 视为一种专用于高性能，低延迟提交日志存储，复制和传播的专用分布式文件系统。

有关 Kafka 的提交日志存储和备份设计的详细信息，请阅读 [此](https://kafka.apache.org/documentation/#design) 页面。

#### Kafka for Stream Processing（Kafka 用于流处理）

仅读取，写入和存储数据流是不够的，目的是实现对流的实时处理。

在 Kafka 中，流处理器是指从输入主题中获取连续数据流，对该输入进行一些处理并生成连续数据流以输出主题的任何东西。

例如，零售应用程序可以接受销售和装运的输入流，并输出根据此数据计算出的重新订购和价格调整流。

可以直接使用生产者和消费者 API 进行简单处理。但是，对于更复杂的转换，Kafka 提供了完全集成的 [Streams API](https://kafka.apache.org/documentation/streams)。这允许构建执行非重要处理的应用程序，这些应用程序计算流的聚合或将流连接在一起。

该功能有助于解决此类应用程序所面临的难题：处理无序数据，在代码更改时重新处理输入，执行状态计算等。

流 API 建立在 Kafka 提供的核心原语之上：它使用生产者和使用者 API 进行输入，使用 Kafka 进行状态存储，并使用相同的组机制来实现流处理器实例之间的容错。

#### Putting the Pieces Together

消息，存储和流处理的这种组合看似不寻常，但这对于 Kafka 作为流平台的角色至关重要。

像 HDFS 这样的分布式文件系统允许存储静态文件以进行批处理。实际上，像这样的系统可以存储和处理过去的历史数据。

传统的企业消息传递系统允许处理将来的消息，这些消息将在您订阅后到达。以这种方式构建的应用程序会在将来的数据到达时对其进行处理。

Kafka 结合了这两种功能，对于将 Kafka 用作流应用程序平台和流数据管道平台而言，这种结合至关重要。

通过结合存储和低延迟订阅，流应用程序可以以相同的方式处理过去和将来的数据。那是一个单一的应用程序可以处理历史数据，存储的数据，而不是在到达最后一条记录时结束，而是可以在将来的数据到达时继续处理。这是流处理的通用概念，它包含批处理以及消息驱动的应用程序。

同样，对于流数据管道，对实时事件的订阅组合使得可以将 Kafka 用于非常低延迟的管道。但是可靠地存储数据的能力使其可以用于必须保证数据传输的关键数据，或与仅定期加载数据或可能停机很长时间进行维护的脱机系统集成。流处理设施使得可以在数据到达时对其进行转换。